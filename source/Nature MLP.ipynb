{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7c8eb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba2266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../Data/features.csv',delimiter=',', skiprows=1) # skip row for column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea8930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = np.array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,\n",
    "       34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66,\n",
    "       68, 70, 72, 74, 76, 78, 80, 82, 83])\n",
    "\n",
    "train_ind = np.array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
    "       35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67,\n",
    "       69, 71, 73, 75, 77, 79, 81])\n",
    "\n",
    "secondary_ind = np.array([ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
    "        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
    "       110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
    "       123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bed8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_life = np.log10(data[:,0])\n",
    "DeltaQ_logVar = data[:,1]\n",
    "DeltaQ_Min = np.log10(-data[:, 2])\n",
    "DeltaQ_Skew = data[:, 3]\n",
    "DeltaQ_Kurt = data[:, 4]\n",
    "QD_Max_2 = data[:, 5]\n",
    "QD_2 = data[:, 6]\n",
    "slope_capacity_fade_2_100 = data[:, 7]\n",
    "intercept_capacity_fade_2_100 = data[:, 8]\n",
    "slope_capacity_fade_91_100 = data[:, 9]\n",
    "intercept_capacity_91_100 = data[:, 10]\n",
    "init_avg_charge_time = data[:, 11]\n",
    "avg_T = data[:, 12]\n",
    "min_IR = data[:, 13]\n",
    "IR_100_2 = data[:, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b96267f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3788253692925331e-16\n"
     ]
    }
   ],
   "source": [
    "X = np.array([DeltaQ_logVar, DeltaQ_Min, DeltaQ_Kurt, QD_Max_2,\n",
    "             slope_capacity_fade_2_100,slope_capacity_fade_91_100, \n",
    "              init_avg_charge_time, min_IR, IR_100_2]).transpose()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "x_train = X[train_ind]\n",
    "y_train = cycle_life[train_ind]\n",
    "\n",
    "x_test = X[test_ind]\n",
    "y_test = cycle_life[test_ind]\n",
    "\n",
    "x_stest = X[secondary_ind]\n",
    "y_stest = cycle_life[secondary_ind]\n",
    "\n",
    "print(np.average(X[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "98d95f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathansun/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:285: UserWarning: The total space of parameters 72 is smaller than n_iter=100. Running 72 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 72 candidates, totalling 288 fits\n",
      "Iteration 1, loss = 3.79737520\n",
      "Iteration 2, loss = 2.06753668\n",
      "Iteration 3, loss = 0.91217273\n",
      "Iteration 4, loss = 0.29983066\n",
      "Iteration 5, loss = 0.15490515\n",
      "Iteration 6, loss = 0.30918362\n",
      "Iteration 7, loss = 0.53778785\n",
      "Iteration 8, loss = 0.66784240\n",
      "Iteration 9, loss = 0.64976724\n",
      "Iteration 10, loss = 0.52490657\n",
      "Iteration 11, loss = 0.35962623\n",
      "Iteration 12, loss = 0.20945811\n",
      "Iteration 13, loss = 0.10694725\n",
      "Iteration 14, loss = 0.06187015\n",
      "Iteration 15, loss = 0.06645960\n",
      "Iteration 16, loss = 0.10247823\n",
      "Iteration 17, loss = 0.14861488\n",
      "Iteration 18, loss = 0.18682350\n",
      "Iteration 19, loss = 0.20608901\n",
      "Iteration 20, loss = 0.20314025\n",
      "Iteration 21, loss = 0.18108965\n",
      "Iteration 22, loss = 0.14711667\n",
      "Iteration 23, loss = 0.10988420\n",
      "Iteration 24, loss = 0.07719617\n",
      "Iteration 25, loss = 0.05431407\n",
      "Iteration 26, loss = 0.04319657\n",
      "Iteration 27, loss = 0.04268786\n",
      "Iteration 28, loss = 0.04941715\n",
      "Iteration 29, loss = 0.05903257\n",
      "Iteration 30, loss = 0.06742739\n",
      "Iteration 31, loss = 0.07171074\n",
      "Iteration 32, loss = 0.07073805\n",
      "Iteration 33, loss = 0.06509604\n",
      "Iteration 34, loss = 0.05659752\n",
      "Iteration 35, loss = 0.04752405\n",
      "Iteration 36, loss = 0.03991655\n",
      "Iteration 37, loss = 0.03510509\n",
      "Iteration 38, loss = 0.03350898\n",
      "Iteration 39, loss = 0.03466390\n",
      "Iteration 40, loss = 0.03744460\n",
      "Iteration 41, loss = 0.04044739\n",
      "Iteration 42, loss = 0.04243344\n",
      "Iteration 43, loss = 0.04267795\n",
      "Iteration 44, loss = 0.04110456\n",
      "Iteration 45, loss = 0.03819226\n",
      "Iteration 46, loss = 0.03473835\n",
      "Iteration 47, loss = 0.03158338\n",
      "Iteration 48, loss = 0.02937574\n",
      "Iteration 49, loss = 0.02842125\n",
      "Iteration 50, loss = 0.02864515\n",
      "Iteration 51, loss = 0.02966816\n",
      "Iteration 52, loss = 0.03095935\n",
      "Iteration 53, loss = 0.03200355\n",
      "Iteration 54, loss = 0.03243512\n",
      "Iteration 55, loss = 0.03211877\n",
      "Iteration 56, loss = 0.03116880\n",
      "Iteration 57, loss = 0.02989580\n",
      "Iteration 58, loss = 0.02868761\n",
      "Iteration 59, loss = 0.02786622\n",
      "Iteration 60, loss = 0.02758123\n",
      "Iteration 61, loss = 0.02778064\n",
      "Iteration 62, loss = 0.02825912\n",
      "Iteration 63, loss = 0.02875352\n",
      "Iteration 64, loss = 0.02904461\n",
      "Iteration 65, loss = 0.02902750\n",
      "Iteration 66, loss = 0.02872766\n",
      "Iteration 67, loss = 0.02826493\n",
      "Iteration 68, loss = 0.02779159\n",
      "Iteration 69, loss = 0.02743583\n",
      "Iteration 70, loss = 0.02726765\n",
      "Iteration 71, loss = 0.02728845\n",
      "Iteration 72, loss = 0.02744068\n",
      "Iteration 73, loss = 0.02763365\n",
      "Iteration 74, loss = 0.02777787\n",
      "Iteration 75, loss = 0.02781549\n",
      "Iteration 76, loss = 0.02773589\n",
      "Iteration 77, loss = 0.02757296\n",
      "Iteration 78, loss = 0.02738659\n",
      "Iteration 79, loss = 0.02723618\n",
      "Iteration 80, loss = 0.02715690\n",
      "Iteration 81, loss = 0.02715004\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=4, random_state=42, shuffle=True),\n",
       "                   estimator=MLPRegressor(random_state=1), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu',\n",
       "                                                       'logistic'],\n",
       "                                        'alpha': [0.0001, 0.001, 0.005],\n",
       "                                        'hidden_layer_sizes': [(200, 200, 100),\n",
       "                                                               (400, 400)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['sgd', 'adam'],\n",
       "                                        'verbose': [True]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor= MLPRegressor(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(200,200,100), (400,400)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.005],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'verbose': [True]\n",
    "}\n",
    "\n",
    "folds = KFold(n_splits = 4, shuffle = True, random_state = 42)\n",
    "model= RandomizedSearchCV(estimator= regressor, n_iter = 100, param_distributions = param_grid ,scoring=\"neg_mean_squared_error\",cv=folds, random_state=42,verbose=2, return_train_score=True, n_jobs = -1)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29386ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMS score:  -0.007867510529424599\n",
      "Best hyperparameters:  {'verbose': True, 'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (400, 400), 'alpha': 0.005, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMS score: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2506f337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='tanh', alpha=0.005, hidden_layer_sizes=(400, 400))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = MLPRegressor(solver=model.best_params_['solver'],\n",
    "                learning_rate=model.best_params_['learning_rate'], \n",
    "                hidden_layer_sizes = model.best_params_['hidden_layer_sizes'], \n",
    "                alpha=model.best_params_['alpha'],\n",
    "                activation=model.best_params_['activation'])\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1402e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  100.83447848155988\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_train) - 10**y_train)**2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4031bc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  285.5270593045472\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_test) - 10**y_test)**2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "be77dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  429.0716678545521\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_stest) - 10**y_stest)**2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a6d99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
