{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9cc2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddecd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('../Data/features.csv',delimiter=',', skiprows=1) # skip row for column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8fef802",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = np.array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,\n",
    "       34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66,\n",
    "       68, 70, 72, 74, 76, 78, 80, 82, 83])\n",
    "\n",
    "train_ind = np.array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
    "       35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67,\n",
    "       69, 71, 73, 75, 77, 79, 81])\n",
    "\n",
    "secondary_ind = np.array([ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
    "        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
    "       110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
    "       123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430167a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_life = np.log10(data[:,0])\n",
    "DeltaQ_logVar = data[:,1]\n",
    "DeltaQ_Min = np.log10(-data[:, 2])\n",
    "DeltaQ_Skew = data[:, 3]\n",
    "DeltaQ_Kurt = data[:, 4]\n",
    "QD_Max_2 = data[:, 5]\n",
    "QD_2 = data[:, 6]\n",
    "slope_capacity_fade_2_100 = data[:, 7]\n",
    "intercept_capacity_fade_2_100 = data[:, 8]\n",
    "slope_capacity_fade_91_100 = data[:, 9]\n",
    "intercept_capacity_91_100 = data[:, 10]\n",
    "init_avg_charge_time = data[:, 11]\n",
    "avg_T = data[:, 12]\n",
    "min_IR = data[:, 13]\n",
    "IR_100_2 = data[:, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5904da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3788253692925331e-16\n"
     ]
    }
   ],
   "source": [
    "X = np.array([DeltaQ_logVar, DeltaQ_Min, DeltaQ_Kurt, QD_Max_2,\n",
    "             slope_capacity_fade_2_100,slope_capacity_fade_91_100, \n",
    "              init_avg_charge_time, min_IR, IR_100_2]).transpose()\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "x_train = X[train_ind]\n",
    "y_train = cycle_life[train_ind]\n",
    "\n",
    "x_test = X[test_ind]\n",
    "y_test = cycle_life[test_ind]\n",
    "\n",
    "x_stest = X[secondary_ind]\n",
    "y_stest = cycle_life[secondary_ind]\n",
    "\n",
    "print(np.average(X[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "854bd357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "Iteration 1, loss = 2.65064227\n",
      "Iteration 2, loss = 1.60034703\n",
      "Iteration 3, loss = 0.82470195\n",
      "Iteration 4, loss = 0.31911262\n",
      "Iteration 5, loss = 0.06387277\n",
      "Iteration 6, loss = 0.01704844\n",
      "Iteration 7, loss = 0.11191811\n",
      "Iteration 8, loss = 0.26680089\n",
      "Iteration 9, loss = 0.40745436\n",
      "Iteration 10, loss = 0.48753889\n",
      "Iteration 11, loss = 0.49350795\n",
      "Iteration 12, loss = 0.43619576\n",
      "Iteration 13, loss = 0.33894274\n",
      "Iteration 14, loss = 0.22813074\n",
      "Iteration 15, loss = 0.12709295\n",
      "Iteration 16, loss = 0.05256690\n",
      "Iteration 17, loss = 0.01291893\n",
      "Iteration 18, loss = 0.00786163\n",
      "Iteration 19, loss = 0.02968788\n",
      "Iteration 20, loss = 0.06594449\n",
      "Iteration 21, loss = 0.10301615\n",
      "Iteration 22, loss = 0.12963107\n",
      "Iteration 23, loss = 0.13926064\n",
      "Iteration 24, loss = 0.13086738\n",
      "Iteration 25, loss = 0.10811997\n",
      "Iteration 26, loss = 0.07763101\n",
      "Iteration 27, loss = 0.04686389\n",
      "Iteration 28, loss = 0.02223073\n",
      "Iteration 29, loss = 0.00773109\n",
      "Iteration 30, loss = 0.00433010\n",
      "Iteration 31, loss = 0.01013272\n",
      "Iteration 32, loss = 0.02124944\n",
      "Iteration 33, loss = 0.03308117\n",
      "Iteration 34, loss = 0.04163866\n",
      "Iteration 35, loss = 0.04452079\n",
      "Iteration 36, loss = 0.04131567\n",
      "Iteration 37, loss = 0.03339430\n",
      "Iteration 38, loss = 0.02324924\n",
      "Iteration 39, loss = 0.01363066\n",
      "Iteration 40, loss = 0.00674265\n",
      "Iteration 41, loss = 0.00370629\n",
      "Iteration 42, loss = 0.00439976\n",
      "Iteration 43, loss = 0.00767350\n",
      "Iteration 44, loss = 0.01183468\n",
      "Iteration 45, loss = 0.01522596\n",
      "Iteration 46, loss = 0.01671281\n",
      "Iteration 47, loss = 0.01594291\n",
      "Iteration 48, loss = 0.01332964\n",
      "Iteration 49, loss = 0.00980431\n",
      "Iteration 50, loss = 0.00644674\n",
      "Iteration 51, loss = 0.00412508\n",
      "Iteration 52, loss = 0.00325467\n",
      "Iteration 53, loss = 0.00373481\n",
      "Iteration 54, loss = 0.00505930\n",
      "Iteration 55, loss = 0.00654203\n",
      "Iteration 56, loss = 0.00756833\n",
      "Iteration 57, loss = 0.00778558\n",
      "Iteration 58, loss = 0.00717818\n",
      "Iteration 59, loss = 0.00601821\n",
      "Iteration 60, loss = 0.00472678\n",
      "Iteration 61, loss = 0.00370599\n",
      "Iteration 62, loss = 0.00320332\n",
      "Iteration 63, loss = 0.00325006\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=4, random_state=42, shuffle=True),\n",
       "                   estimator=MLPRegressor(random_state=1), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'activation': ['tanh', 'relu',\n",
       "                                                       'logistic'],\n",
       "                                        'alpha': [0.0001, 0.001, 0.005],\n",
       "                                        'hidden_layer_sizes': [(100, 100, 50),\n",
       "                                                               (250, 250),\n",
       "                                                               (1000,)],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['sgd', 'adam'],\n",
       "                                        'verbose': [True]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor= MLPRegressor(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(100,100,50), (250,250)],\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.005],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'verbose': [True]\n",
    "}\n",
    "\n",
    "folds = KFold(n_splits = 4, shuffle = True, random_state = 42)\n",
    "model= RandomizedSearchCV(estimator= regressor, n_iter = 100, param_distributions = param_grid ,scoring=\"neg_mean_squared_error\",cv=folds, random_state=42,verbose=2, return_train_score=True, n_jobs = -1)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b3025b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMS score:  -0.009895494118874255\n",
      "Best hyperparameters:  {'verbose': True, 'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (1000,), 'alpha': 0.005, 'activation': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMS score: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d321f933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.005, hidden_layer_sizes=(1000,),\n",
       "             learning_rate='adaptive')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = MLPRegressor(solver=model.best_params_['solver'],\n",
    "                learning_rate=model.best_params_['learning_rate'], \n",
    "                hidden_layer_sizes = model.best_params_['hidden_layer_sizes'], \n",
    "                alpha=model.best_params_['alpha'],\n",
    "                activation=model.best_params_['activation'])\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e24aa4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  258.7207771339234\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_train) - 10**y_train)**2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5bcf4f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  301.09738606551156\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_test) - 10**y_test)**2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "add54fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  462.4829373979832\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(np.average((10**regressor.predict(x_stest) - 10**y_stest)**2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734895f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
