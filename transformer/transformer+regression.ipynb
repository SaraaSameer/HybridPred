{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This uses the discharge-voltage curves at each cycle as raw data. Dimensionality is $(100,1000)$, with 100 cycles and 1000 voltage steps at which discharge is measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(r'../Data/discharge_curves.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(data[\"discharge_curves\"].values) # reshape data\n",
    "y = data[\"cycle_life\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 99, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x) # 124 batteries, 99 cycles, discharge measured at 1000 voltage steps per cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors and concatenate features and labels\n",
    "x = torch.Tensor(x)\n",
    "y = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embeddings = nn.Parameter(torch.randn(len(x), 99, 1000))\n",
    "\n",
    "# Add position embedding into patch embedding\n",
    "input_embeddings = x + position_embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ind = np.array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,\n",
    "       34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66,\n",
    "       68, 70, 72, 74, 76, 78, 80, 82, 83])\n",
    "\n",
    "train_ind = np.array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33,\n",
    "       35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67,\n",
    "       69, 71, 73, 75, 77, 79, 81])\n",
    "\n",
    "secondary_ind = np.array([ 84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,\n",
    "        97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109,\n",
    "       110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122,\n",
    "       123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(torch.Tensor(x[train_ind]),torch.Tensor(y[train_ind]))\n",
    "test = TensorDataset(torch.Tensor(x[test_ind]),torch.Tensor(y[test_ind]))\n",
    "stest = TensorDataset(torch.Tensor(x[secondary_ind]),torch.Tensor(y[secondary_ind]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([124, 99, 1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "d_model = 1000\n",
    "nhead = 8\n",
    "batch_size = 3\n",
    "nepoch = 1\n",
    "batch_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Output embedding size: torch.Size([10, 99, 1000])\n"
     ]
    }
   ],
   "source": [
    "num_heads = 8\n",
    "num_layers = 12\n",
    "\n",
    "# Define Transformer encoders' stack\n",
    "transformer_encoder_layer = nn.TransformerEncoderLayer(\n",
    "           d_model=d_model, nhead=num_heads,\n",
    "           dim_feedforward=int(d_model * 4),\n",
    "           dropout=0.1)\n",
    "transformer_encoder = nn.TransformerEncoder(\n",
    "           encoder_layer=transformer_encoder_layer,\n",
    "           num_layers=num_layers)\n",
    "\n",
    "# Forward pass\n",
    "output_embeddings = transformer_encoder(input_embeddings[:10])\n",
    "print(f' Output embedding size: {output_embeddings.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = nn.Linear(d_model, 1) \n",
    "output_regression = regressor(torch.sum(output_embeddings, dim = 1))\n",
    "output_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "\n",
    "        self.transformer = transformer_encoder\n",
    "        torch.nn.init.xavier_uniform(self.transformer.weight)\n",
    "        self.linear = regressor\n",
    "        torch.nn.init.xavier_uniform(self.linear.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerEncoder' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m use_cuda \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Load nodel, loss function, and optimizer\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m FullModel()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mFullModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39msuper\u001b[39m(FullModel, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      6\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer \u001b[39m=\u001b[39m transformer_encoder\n\u001b[0;32m----> 7\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mxavier_uniform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mweight)\n\u001b[1;32m      8\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m regressor\n\u001b[1;32m      9\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mxavier_uniform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear\u001b[39m.\u001b[39mweight)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransformerEncoder' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Load nodel, loss function, and optimizer\n",
    "model = FullModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Load batch image\n",
    "train_dataset = TensorDataset(torch.Tensor(x[train_ind]),torch.Tensor(y[train_ind]))\n",
    "# train_dataloader = DataLoader(train_dataset, num_workers=1, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Fine tuning loop\n",
    "for i in range(1):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0.0\n",
    "\n",
    "    for train_input, train_label in train_dataset[:10]:\n",
    "        output = model(train_input.to(device))\n",
    "        print(output)\n",
    "        # loss = criterion(output, train_label.to(device))\n",
    "        # acc = (output.argmax(dim=1) == train_label.to(device)).sum().item()\n",
    "        # total_acc_train += acc\n",
    "        # total_loss_train += loss.item()\n",
    "\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "    # print(f'Epochs: {i + 1} | Loss: {total_loss_train / len(train_dataset): .3f} | Accuracy: {total_acc_train / len(train_dataset): .3f}')\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toyota",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
